{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early morning 03.00 - 06.00\n",
    "# Morning 06.00 - 12.00\n",
    "# Afternoon 12.00 - 17.00\n",
    "# Evning 10.00 - 20.00\n",
    "# Night 20.00 - 03.00 \n",
    "\n",
    "def convert_timeperiod(time):\n",
    "    time = int(time)\n",
    "    hour = int(time / 100)\n",
    "    minute = (time % 100)//30\n",
    "    time  =hour + minute\n",
    "\n",
    "    if   6 <= time <= 11 :\n",
    "        result = 'Morning'\n",
    "    elif 11 <= time <= 17 :\n",
    "        result = 'Afternoon'\n",
    "    elif 17 <= time <= 20 :\n",
    "        result = 'Evening'\n",
    "    elif 20 <= time <= 24 :\n",
    "        result = 'Night'\n",
    "    elif time <= 3 :\n",
    "        result = 'Night'     \n",
    "    else:\n",
    "        result= 'EarlyMorning'  \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_preprocess(data,process=None,mode=None):\n",
    "    if mode:\n",
    "        process = process.fit(data)\n",
    "        con_data = process.transform(data)\n",
    "    else:\n",
    "        con_data = process.transform(data)\n",
    "    return con_data,process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eveulatemodel(y_true,predict):\n",
    "    score =  mean_squared_error(y_true,predict)\n",
    "    r2score =  r2_score(y_true,predict)\n",
    "    print(f'rmse score {score}')\n",
    "    print(f'r2 score {r2score}')\n",
    "\n",
    "    plt.scatter(predict,y_true,c='red')\n",
    "\n",
    "    p1 = max(max(predict), max(y_true))\n",
    "    p2 = min(min(predict), min(y_true))\n",
    "    plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "    plt.xlabel('True Values', fontsize=15)\n",
    "    plt.ylabel('Predictions', fontsize=15)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    return score,r2_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedata(data):\n",
    "    data['CRSDepTime'] = data.CRSDepTimeHour.astype('string')+ data.CRSDepTimeMinute.astype('string').str.zfill(2)\n",
    "    data['WheelsOff'] = data.WheelsOffHour.astype('string')+ data.WheelsOffMinute.astype('string').str.zfill(2)\n",
    "    data['CRSArrTime'] = data.CRSArrTimeHour.astype('string')+ data.CRSArrTimeMinute.astype('string').str.zfill(2)\n",
    "    data['origin_state'] = data['OriginCityName'].apply(lambda x: x[x.rfind(' ')+1:])\n",
    "    data['dest_state'] = data['DestCityName'].apply(lambda x: x[x.rfind(' ')+1:])\n",
    "    data['state_combine'] = data['origin_state'] +'_' + data['dest_state']\n",
    "    data['location_yn'] = (data['origin_state'] == data['dest_state']).astype('int')\n",
    "    data.Holidays = (data.Holidays).astype('int')\n",
    "\n",
    "    data['CRSDepTimeHourDis'] = data.CRSDepTime.apply(lambda x: convert_timeperiod(x))\n",
    "    data['WheelsOffHourDis'] = data.WheelsOff.apply(lambda x: convert_timeperiod(x))\n",
    "    data['CRSArrTimeHourDis'] = data.CRSArrTime.apply(lambda x: convert_timeperiod(x))\n",
    "\n",
    "    top_state = ['CA_CA', 'TX_TX', 'NY_FL', 'FL_NY', 'CA_TX', 'TX_CA', 'FL_TX', 'HI_HI', 'TX_FL', 'FL_GA', 'CA_NV', 'NV_CA', 'GA_FL', 'CA_WA', 'CA_AZ', 'AZ_CA', 'WA_CA', 'CA_CO', 'CO_CA', 'FL_NC', 'NC_FL', 'TX_CO', 'CO_TX', 'NJ_FL', 'FL_NJ', 'IL_FL', 'FL_IL', 'CA_HI', 'FL_FL', 'HI_CA', 'CO_CO', 'NC_NC', 'NY_NC', 'NY_IL', 'IL_NY', 'NC_NY', 'IL_TX', 'TX_IL', 'WA_WA', 'PA_FL', 'FL_PA', 'LA_TX', 'OR_CA', 'TX_LA', 'CA_OR', 'CA_UT', 'TX_GA', 'DC_FL', 'UT_CA', 'GA_TX']\n",
    "\n",
    "    cat_col = ['Marketing_Airline_Network', 'DayofWeek','Holidays', 'CRSDepTimeHourDis', 'WheelsOffHourDis','CRSArrTimeHourDis', 'state_combine', 'location_yn']\n",
    "    int_col = [ 'DepDelay', 'TaxiOut', 'CRSElapsedTime','ActualElapsedTime', 'Distance', 'WeatherDelay']\n",
    "    data = data[cat_col + int_col]\n",
    "    data['state_combine'] = data['state_combine'].apply(lambda x: x if x in top_state else 'Other')\n",
    "    data[cat_col] = data[cat_col].astype('category')\n",
    "    data[int_col] = data[int_col].astype('int')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedata_prod(data):\n",
    "    data['CRSDepTime'] = data.CRSDepTimeHour.astype('string')+ data.CRSDepTimeMinute.astype('string').str.zfill(2)\n",
    "    data['WheelsOff'] = data.WheelsOffHour.astype('string')+ data.WheelsOffMinute.astype('string').str.zfill(2)\n",
    "    data['CRSArrTime'] = data.CRSArrTimeHour.astype('string')+ data.CRSArrTimeMinute.astype('string').str.zfill(2)\n",
    "    data['origin_state'] = data['OriginCityName'].apply(lambda x: x[x.rfind(' ')+1:])\n",
    "    data['dest_state'] = data['DestCityName'].apply(lambda x: x[x.rfind(' ')+1:])\n",
    "    data['state_combine'] = data['origin_state'] +'_' + data['dest_state']\n",
    "    data['location_yn'] = (data['origin_state'] == data['dest_state']).astype('int')\n",
    "    data.Holidays = (data.Holidays).astype('int')\n",
    "\n",
    "    data['CRSDepTimeHourDis'] = data.CRSDepTime.apply(lambda x: convert_timeperiod(x))\n",
    "    data['WheelsOffHourDis'] = data.WheelsOff.apply(lambda x: convert_timeperiod(x))\n",
    "    data['CRSArrTimeHourDis'] = data.CRSArrTime.apply(lambda x: convert_timeperiod(x))\n",
    "\n",
    "    top_state = ['CA_CA', 'TX_TX', 'NY_FL', 'FL_NY', 'CA_TX', 'TX_CA', 'FL_TX', 'HI_HI', 'TX_FL', 'FL_GA', 'CA_NV', 'NV_CA', 'GA_FL', 'CA_WA', 'CA_AZ', 'AZ_CA', 'WA_CA', 'CA_CO', 'CO_CA', 'FL_NC', 'NC_FL', 'TX_CO', 'CO_TX', 'NJ_FL', 'FL_NJ', 'IL_FL', 'FL_IL', 'CA_HI', 'FL_FL', 'HI_CA', 'CO_CO', 'NC_NC', 'NY_NC', 'NY_IL', 'IL_NY', 'NC_NY', 'IL_TX', 'TX_IL', 'WA_WA', 'PA_FL', 'FL_PA', 'LA_TX', 'OR_CA', 'TX_LA', 'CA_OR', 'CA_UT', 'TX_GA', 'DC_FL', 'UT_CA', 'GA_TX']\n",
    "\n",
    "    # cat_col = ['Marketing_Airline_Network', 'DayofWeek','Holidays', 'CRSDepTimeHourDis', 'WheelsOffHourDis','CRSArrTimeHourDis', 'state_combine', 'location_yn']\n",
    "    # int_col = [ 'DepDelay', 'TaxiOut', 'CRSElapsedTime', 'Distance', 'WeatherDelay']\n",
    "    # data = data[cat_col + int_col]\n",
    "    data['state_combine'] = data['state_combine'].apply(lambda x: x if x in top_state else 'Other')\n",
    "    # data[cat_col] = data[cat_col].astype('category')\n",
    "    # data[int_col] = data[int_col].astype('int')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('features_added.parquet')\n",
    "df_par= df.query(\"Year >=2022\")\n",
    "df_par,state = preparedata(df_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_col = [ 'FlightDate', 'CRSElapsedTime', 'Distance'\n",
    "            ,'Marketing_Airline_Network', 'DayofWeek','Holidays'\n",
    "            ,'CRSDepTimeHour','CRSDepTimeMinute' ,'CRSArrTimeHour','CRSArrTimeMinute'\n",
    "            ,'DestCityName','OriginCityName'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_record = 3000\n",
    "df_sendsamle = df[used_col].sample(sample_record).sort_values('FlightDate').reset_index(drop=True)\n",
    "df_sendsamle['FlightID'] = [str(uuid.uuid4()) for i in range(sample_record) ]\n",
    "df_sendsamle[['DepDelay', 'TaxiOut','WeatherDelay']] = 0.0\n",
    "df_sendsamle[['WheelsOffHour','WheelsOffMinute']] = df_sendsamle[['CRSDepTimeHour', 'CRSDepTimeMinute']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "new_data = []\n",
    "\n",
    "num_row = 0\n",
    "\n",
    "for index,record in df_sendsamle.iterrows():    \n",
    "    num_row = 0\n",
    "    for row in range(5):\n",
    "        \n",
    "        if record['WeatherDelay']:\n",
    "            depdelay_weather = [0,random.randint(0,30) ][random.randint(0,1)]\n",
    "            record['WeatherDelay'] += depdelay_weather\n",
    "\n",
    "        else:\n",
    "            depdelay_taxi = [0,random.randint(0,30) ][random.randint(0,1)]\n",
    "            if record['TaxiOut']:\n",
    "               \n",
    "                if depdelay_taxi:\n",
    "                    record['TaxiOut'] += random.randint(0,30) \n",
    "                else:\n",
    "                    record['WeatherDelay'] += random.randint(1,30)     \n",
    "            else:\n",
    "                depdelay_pos = random.randint(1,30*(1+num_row))\n",
    "                depdelay_neg = random.randint(-30*(1+num_row),-1)\n",
    "                depdelay_ran = [depdelay_neg,0,depdelay_pos][random.randint(0,2)]\n",
    "\n",
    "                if record['DepDelay']:                  \n",
    "\n",
    "                    if depdelay_ran <=0:\n",
    "                        # record['DepDelay'] += depdelay_ran\n",
    "                        record['TaxiOut'] += random.randint(1,30) \n",
    "                    else :\n",
    "                        record['DepDelay'] += depdelay_ran\n",
    "\n",
    "                else:                    \n",
    "                    record['DepDelay'] += depdelay_ran\n",
    "        num_row+=1\n",
    "        _record = record.copy()\n",
    "        new_data.append(_record)\n",
    "df_new = pd.DataFrame(new_data)\n",
    "\n",
    "df_new['new_taxi'] = pd.to_datetime((df_new.WheelsOffHour.astype('string') + df_new.WheelsOffMinute.astype('string').str.zfill(2)),format='%H%M') +  pd.to_timedelta(df_new.DepDelay + df_new.TaxiOut, unit='m')\n",
    "df_new['WheelsOffHour'] = df_new['new_taxi'].dt.hour\n",
    "df_new['WheelsOffMinute'] = df_new['new_taxi'].dt.minute\n",
    "df_new.drop('new_taxi',axis=1,inplace=True)\n",
    "\n",
    "df_all_sample= pd.concat([df_new,df_sendsamle],axis=0)\n",
    "df_all_sample = df_all_sample.sort_values(['FlightID','DepDelay','TaxiOut','WeatherDelay']).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sample= pd.concat([df_new,df_sendsamle],axis=0)\n",
    "df_all_sample = df_all_sample.sort_values(['FlightID','DepDelay','TaxiOut','WeatherDelay']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sample.to_csv('All_2023-10-23.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sendsamle_json = df_all_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparedata_prod(df_sendsamle_json[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def preparedata_prod(data):\n",
    "    top_state = ['CA_CA', 'TX_TX', 'NY_FL', 'FL_NY', 'CA_TX', 'TX_CA', 'FL_TX', 'HI_HI', 'TX_FL', 'FL_GA', 'CA_NV', 'NV_CA', 'GA_FL', 'CA_WA', 'CA_AZ', 'AZ_CA', 'WA_CA', 'CA_CO', 'CO_CA', 'FL_NC', 'NC_FL', 'TX_CO', 'CO_TX', 'NJ_FL', 'FL_NJ', 'IL_FL', 'FL_IL', 'CA_HI', 'FL_FL', 'HI_CA', 'CO_CO', 'NC_NC', 'NY_NC', 'NY_IL', 'IL_NY', 'NC_NY', 'IL_TX', 'TX_IL', 'WA_WA', 'PA_FL', 'FL_PA', 'LA_TX', 'OR_CA', 'TX_LA', 'CA_OR', 'CA_UT', 'TX_GA', 'DC_FL', 'UT_CA', 'GA_TX']\n",
    "    used_val =['FlightDate','CRSDepTimeHour','CRSDepTimeMinute','CRSArrTimeHour','CRSArrTimeMinute','DestCityName','OriginCityName','FlightID','WheelsOffHour','WheelsOffMinute','CRSDepTime','WheelsOff','CRSArrTime','dest_state','origin_state']\n",
    "\n",
    "    data['CRSDepTime'] = str(data['CRSDepTimeHour']) + str(data['CRSDepTimeMinute']).zfill(2)\n",
    "    data['WheelsOff'] = str(data['WheelsOffHour']) + str(data['WheelsOffMinute']).zfill(2) \n",
    "    data['CRSArrTime'] = str(data['CRSArrTimeHour']) + str(data['CRSArrTimeMinute']).zfill(2)\n",
    "    data['origin_state'] = data['OriginCityName'][data['OriginCityName'].rfind(' ')+1:]\n",
    "    data['dest_state'] = data['DestCityName'][data['DestCityName'].rfind(' ')+1:]\n",
    "    data['state_combine'] = data['origin_state'] +'_' + data['dest_state']\n",
    "    data['location_yn'] = int(data['origin_state'] == data['dest_state'])\n",
    "    data['Holidays'] = int(data['Holidays'])\n",
    "    data['CRSDepTimeHourDis'] = convert_timeperiod(data['CRSDepTime'])\n",
    "    data['WheelsOffHourDis'] = convert_timeperiod(data['WheelsOff'])\n",
    "    data['CRSArrTimeHourDis'] = convert_timeperiod(data['CRSArrTime'])\n",
    "    data['state_combine'] = data['state_combine']  if data['state_combine'] in top_state else 'Other'\n",
    "    for i in used_val:\n",
    "        del data[i]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data = [preparedata_prod(data) for data in copy.deepcopy(df_sendsamle_json[50:60])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sendsamle_json[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_remain,train = train_test_split(df_par,test_size=0.6,random_state=1)\n",
    "test,val = train_test_split(_remain,test_size=0.5,random_state=1)\n",
    "\n",
    "train_x = train.drop('ActualElapsedTime',axis=1).to_dict(orient='records')\n",
    "train_y = train['ActualElapsedTime'].values\n",
    "val_x = val.drop('ActualElapsedTime',axis=1).to_dict(orient='records')\n",
    "val_y = val['ActualElapsedTime'].values\n",
    "\n",
    "dv= DictVectorizer()\n",
    "train_x_dv,dv = convert_preprocess(train_x,dv,'train')\n",
    "val_x_dv,dv = convert_preprocess(val_x,dv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'FlightDate': ('2022-02-11 00:00:00'),\n",
    "  'CRSElapsedTime': 250.0,\n",
    "  'Distance': 1440.0,\n",
    "  'Marketing_Airline_Network': 'WN',\n",
    "  'DayofWeek': 4,\n",
    "  'Holidays': False,\n",
    "  'CRSDepTimeHour': 8,\n",
    "  'CRSDepTimeMinute': 50,\n",
    "  'CRSArrTimeHour': 12,\n",
    "  'CRSArrTimeMinute': 0,\n",
    "  'DestCityName': 'Tucson, AZ',\n",
    "  'OriginCityName': 'Chicago, IL',\n",
    "  'FlightID': '000084da-fd98-4220-b92c-3eb2e9620aa0',\n",
    "  'DepDelay': 39.0,\n",
    "  'TaxiOut': 0.0,\n",
    "  'WeatherDelay': 0.0,\n",
    "  'WheelsOffHour': 9,\n",
    "  'WheelsOffMinute': 29},\n",
    "{'FlightDate': ('2022-02-11 00:00:00'),\n",
    "  'CRSElapsedTime': 250.0,\n",
    "  'Distance': 1440.0,\n",
    "  'Marketing_Airline_Network': 'WN',\n",
    "  'DayofWeek': 4,\n",
    "  'Holidays': False,\n",
    "  'CRSDepTimeHour': 8,\n",
    "  'CRSDepTimeMinute': 50,\n",
    "  'CRSArrTimeHour': 12,\n",
    "  'CRSArrTimeMinute': 0,\n",
    "  'DestCityName': 'Tucson, AZ',\n",
    "  'OriginCityName': 'Chicago, IL',\n",
    "  'FlightID': '000084da-fd98-4220-b92c-3eb2e9620aa0',\n",
    "  'DepDelay': 39.0,\n",
    "  'TaxiOut': 0.0,\n",
    "  'WeatherDelay': 0.0,\n",
    "  'WheelsOffHour': 9,\n",
    "  'WheelsOffMinute': 29}]\n",
    "\n",
    "new_value = [20, 50]\n",
    "\n",
    "data_with_predict = [{**d, 'predict': new_value ,'test':2} for d in data]\n",
    "model.__hash__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test,train = train_test_split(df_par,test_size=0.6,random_state=1)\n",
    "\n",
    "train_x = train.drop('ActualElapsedTime',axis=1).to_dict(orient='records')\n",
    "train_y = train['ActualElapsedTime'].values\n",
    "test_x = test.drop('ActualElapsedTime',axis=1).to_dict(orient='records')\n",
    "test_y = test['ActualElapsedTime'].values\n",
    "\n",
    "dv= DictVectorizer()\n",
    "train_x_dv,dv = convert_preprocess(train_x,dv,'train')\n",
    "test_x_dv,dv = convert_preprocess(test_x,dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none\n",
    "model = LinearRegression()\n",
    "model.fit(train_x_dv,train_y)\n",
    "predict = model.predict(val_x_dv)\n",
    "eveulatemodel(val_y,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "dfs = dv.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dfs,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "     LinearRegression()\n",
    "    )\n",
    "pipeline.fit(train_x,test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none\n",
    "model = LinearRegression()\n",
    "model.fit(train_x_dv,train_y)\n",
    "predict = model.predict(test_x_dv)\n",
    "eveulatemodel(test_y,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predict'] = predict\n",
    "test['dif'] = (test['predict'] - test['ActualElapsedTime']).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = 25\n",
    "(len(test.query(\"dif >@thread or dif < -@thread\")) / len(test.query(\"dif <@thread and dif > -@thread\")))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickle.dump(model, open('model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('../../artifact/model.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dv, open('dv.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../../data/All_2023-10-23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.iloc[:10000].to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/samplerecord-smallest.json','w+') as file:\n",
    "    file.write(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "feil = open('../../data/samplerecord-small.json','r')  \n",
    "file = json.load(feil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FlightDate': '2021-08-09 00:00:00',\n",
       " 'CRSElapsedTime': 135.0,\n",
       " 'Distance': 825.0,\n",
       " 'Marketing_Airline_Network': 'WN',\n",
       " 'DayofWeek': 0,\n",
       " 'Holidays': False,\n",
       " 'CRSDepTimeHour': 6,\n",
       " 'CRSDepTimeMinute': 0,\n",
       " 'CRSArrTimeHour': 8,\n",
       " 'CRSArrTimeMinute': 15,\n",
       " 'DestCityName': 'Chicago, IL',\n",
       " 'OriginCityName': 'New Orleans, LA',\n",
       " 'FlightID': '000011fa-f374-4784-ae11-398ed8900ac1',\n",
       " 'DepDelay': -29.0,\n",
       " 'TaxiOut': 0.0,\n",
       " 'WeatherDelay': 0.0,\n",
       " 'WheelsOffHour': 5,\n",
       " 'WheelsOffMinute': 31}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
